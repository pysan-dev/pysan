{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics\n",
    "\n",
    "> Compute descriptive statistics on sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_recurrent(sequence):\n",
    "\t\"Returns true if the given sequence is recurrent (elements can exist more than once), otherwise returns false.\"\t\n",
    "\telement_counts = get_element_counts(sequence)\n",
    "\t\n",
    "\ttruths = [count > 1 for element, count in element_counts.items()]\n",
    "\t\n",
    "\tif True in truths:\n",
    "\t\treturn True\n",
    "\treturn False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_entropy(sequence):\n",
    "\t\"Computes the normalised [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) of a given sequence, using the [scipy.stats.entropy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html) implementation. Note that this measure is insensitive to transition frequency or event order, so should be used in conjunction with other measures.\"\n",
    "\t\n",
    "\talphabet = get_alphabet(sequence)\n",
    "\n",
    "\tentropy = 0\n",
    "\tfor state in alphabet:\n",
    "\t\tproportion_occurances = sequence.count(state) / len(sequence)\n",
    "\t\tentropy += proportion_occurances * math.log(proportion_occurances)\n",
    "\t\n",
    "\tmaximal_occurances = 1 / len(alphabet)\n",
    "\talphabet_entropy = sum([maximal_occurances * math.log(maximal_occurances) for x in alphabet])\n",
    "\t\n",
    "\tif alphabet_entropy == 0:\n",
    "\t\treturn 0\n",
    "\t\n",
    "\treturn -entropy / -alphabet_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_turbulence(sequence):\n",
    "\t\"Computes turbulence for a given sequence, based on [Elzinga & Liefbroer's 2007 definition](https://www.researchgate.net/publication/225402919_De-standardization_of_Family-Life_Trajectories_of_Young_Adults_A_Cross-National_Comparison_Using_Sequence_Analysis) which is also implemented in the [TraMineR](http://traminer.unige.ch/doc/seqST.html) sequence analysis library.\"\n",
    "\n",
    "\tphi = get_ndistinct_subsequences(sequence)\n",
    "\n",
    "\t#print('phi', phi)\n",
    "\n",
    "\tstate_durations = [value for key, value in get_spells(sequence)]\n",
    "\n",
    "\t#print('durations', state_durations)\n",
    "\t#print('mean duration', statistics.mean(state_durations))\n",
    "\n",
    "\tvariance_of_state_durations = statistics.variance(state_durations)\n",
    "\n",
    "\t#print('variance', variance_of_state_durations)\n",
    "\n",
    "\ttbar = statistics.mean(state_durations)\n",
    "\n",
    "\tmaximum_state_duration_variance = (len(sequence) - 1) * (1 - tbar) ** 2\n",
    "\n",
    "\t#print('smax', maximum_state_duration_variance)\n",
    "\n",
    "\ttop_right = maximum_state_duration_variance + 1\n",
    "\tbot_right = variance_of_state_durations + 1\n",
    "\n",
    "\tturbulence = math.log2(phi * (top_right / bot_right))\n",
    "\n",
    "\t#print('turbulence', turbulence)\n",
    "\n",
    "\treturn turbulence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_complexity(sequence):\n",
    "\t\"Computes the complexity of a given sequence, based on TraMineR's [seqici](http://traminer.unige.ch/doc/seqici.html) method.\"\n",
    "\t\n",
    "\talphabet = get_alphabet(sequence)\n",
    "\n",
    "\tpre_log = 1 / len(alphabet)\n",
    "\thmax = -math.log(pre_log)\n",
    "\t#print('hmax', hmax)\n",
    "\tif hmax == 0:\n",
    "\t\treturn 0 # all identical elements, no complexity\n",
    "\n",
    "\ths = get_entropy(sequence)\n",
    "\t#print('hs', hs)\n",
    "\n",
    "\tqs = get_ntransitions(sequence)\n",
    "\t#print('qs', qs)\n",
    "\n",
    "\tqmax = len(sequence) - 1\n",
    "\t#print('qmax', qmax)\n",
    "\n",
    "\tnorm_transitions = qs / qmax\n",
    "\tnorm_entropy = hs / hmax\n",
    "\n",
    "\t#print('nt', norm_transitions)\n",
    "\t#print('ne', norm_entropy)\n",
    "\n",
    "\tcomplexity = math.sqrt(norm_transitions * norm_entropy)\n",
    "\n",
    "\t#print('complexity', complexity)\n",
    "\treturn complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_routine(sequence, duration):\n",
    "\t\"Computes a normalised measure of routine within a sequence for a given duration within that sequence. E.g. with a sequence where each element is one day, calling get_routine() with a duration of 7 would look at weekly routines. Note that this routine measure is identical to the multisequence measure of synchrony, but applied within-sequence in duration length chunks.\"\n",
    "\t\n",
    "\tif len(sequence) % duration != 0:\n",
    "\t\traise Exception('sequence not divisible by interval, check data input')\n",
    "\t\n",
    "\tnum_cycles = int(len(sequence) / duration)\n",
    "\tcycles = [sequence[n * duration:n * duration + duration] for n in range(num_cycles)]\n",
    "\t\n",
    "\treturn pysan_ms.get_synchrony(cycles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
