{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics\n",
    "\n",
    "> Compute descriptive statistics on sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Summary statistics are a great way to gain insights into single sequences, but can also be used for comparisons between sequences. Methods for computing summary statistics on a single sequence exist in the `statistics` module, and include recurrence, entropy, turbulence, complexity, and routine statistics. This module doesn't contain any plotting methods as each of the summary statistics is a single number. Visit the `attributes` module for plotting capabilities for summary statistics across collections of sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pysan.elements import get_element_counts\n",
    "def is_recurrent(sequence):\n",
    "    \"Returns true if the given sequence is recurrent (elements can exist more than once), otherwise returns false.\"\t\n",
    "    element_counts = get_element_counts(sequence)\n",
    "\n",
    "    truths = [count > 1 for element, count in element_counts.items()]\n",
    "\n",
    "    if True in truths:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [1,1,2,1,2,2,3,1,1,2,2,1,2,2,3,1,1,2]\n",
    "is_recurrent(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [1,4,2,5,3]\n",
    "is_recurrent(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pysan.elements import get_alphabet\n",
    "import math\n",
    "def get_entropy(sequence):\n",
    "    \"Computes the normalised [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) of a given sequence, using the [scipy.stats.entropy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html) implementation. Note that this measure is insensitive to transition frequency or event order, so should be used in conjunction with other measures.\"\n",
    "\n",
    "    alphabet = get_alphabet(sequence)\n",
    "\n",
    "    entropy = 0\n",
    "    for state in alphabet:\n",
    "        proportion_occurances = sequence.count(state) / len(sequence)\n",
    "        entropy += proportion_occurances * math.log(proportion_occurances)\n",
    "\n",
    "    maximal_occurances = 1 / len(alphabet)\n",
    "    alphabet_entropy = sum([maximal_occurances * math.log(maximal_occurances) for x in alphabet])\n",
    "\n",
    "    if alphabet_entropy == 0:\n",
    "        return 0\n",
    "\n",
    "    return -entropy / -alphabet_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8783471047618535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [1,1,2,1,2,2,3,1,1,2,2,1,2,2,3,1,1,2]\n",
    "get_entropy(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pysan.subsequences import get_ndistinct_subsequences\n",
    "from pysan.spells import get_spells\n",
    "import statistics\n",
    "def get_turbulence(sequence):\n",
    "    \"Computes turbulence for a given sequence, based on [Elzinga & Liefbroer's 2007 definition](https://www.researchgate.net/publication/225402919_De-standardization_of_Family-Life_Trajectories_of_Young_Adults_A_Cross-National_Comparison_Using_Sequence_Analysis) which is also implemented in the [TraMineR](http://traminer.unige.ch/doc/seqST.html) sequence analysis library.\"\n",
    "\n",
    "    phi = get_ndistinct_subsequences(sequence)\n",
    "\n",
    "    #print('phi', phi)\n",
    "\n",
    "    state_durations = [value for key, value in get_spells(sequence)]\n",
    "\n",
    "    #print('durations', state_durations)\n",
    "    #print('mean duration', statistics.mean(state_durations))\n",
    "\n",
    "    variance_of_state_durations = statistics.variance(state_durations)\n",
    "\n",
    "    #print('variance', variance_of_state_durations)\n",
    "\n",
    "    tbar = statistics.mean(state_durations)\n",
    "\n",
    "    maximum_state_duration_variance = (len(sequence) - 1) * (1 - tbar) ** 2\n",
    "\n",
    "    #print('smax', maximum_state_duration_variance)\n",
    "\n",
    "    top_right = maximum_state_duration_variance + 1\n",
    "    bot_right = variance_of_state_durations + 1\n",
    "\n",
    "    turbulence = math.log2(phi * (top_right / bot_right))\n",
    "\n",
    "    #print('turbulence', turbulence)\n",
    "\n",
    "    return turbulence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.846405533635949"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [1,1,2,1,2,2,3,1,1,2,2,1,2,2,3,1,1,2]\n",
    "get_turbulence(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pysan.elements import get_alphabet\n",
    "from pysan.transitions import get_ntransitions\n",
    "def get_complexity(sequence):\n",
    "    \"Computes the complexity of a given sequence, based on TraMineR's [seqici](http://traminer.unige.ch/doc/seqici.html) method.\"\n",
    "\n",
    "    alphabet = get_alphabet(sequence)\n",
    "\n",
    "    pre_log = 1 / len(alphabet)\n",
    "    hmax = -math.log(pre_log)\n",
    "    #print('hmax', hmax)\n",
    "    if hmax == 0:\n",
    "        return 0 # all identical elements, no complexity\n",
    "\n",
    "    hs = get_entropy(sequence)\n",
    "    #print('hs', hs)\n",
    "\n",
    "    qs = get_ntransitions(sequence)\n",
    "    #print('qs', qs)\n",
    "\n",
    "    qmax = len(sequence) - 1\n",
    "    #print('qmax', qmax)\n",
    "\n",
    "    norm_transitions = qs / qmax\n",
    "    norm_entropy = hs / hmax\n",
    "\n",
    "    #print('nt', norm_transitions)\n",
    "    #print('ne', norm_entropy)\n",
    "\n",
    "    complexity = math.sqrt(norm_transitions * norm_entropy)\n",
    "\n",
    "    #print('complexity', complexity)\n",
    "    return complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7192547565866093"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [1,1,2,1,2,2,3,1,1,2,2,1,2,2,3,1,1,2]\n",
    "get_complexity(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#from pysan.attributes import get_synchrony\n",
    "def get_routine(sequence, duration):\n",
    "    \"Computes a normalised measure of routine within a sequence for a given duration within that sequence. E.g. with a sequence where each element is one day, calling get_routine() with a duration of 7 would look at weekly routines. Note that this routine measure is identical to the multisequence measure of synchrony, but applied within-sequence in duration length chunks.\"\n",
    "\n",
    "    if len(sequence) % duration != 0:\n",
    "        raise Exception('sequence not divisible by interval, please check data input')\n",
    "\n",
    "    num_cycles = int(len(sequence) / duration)\n",
    "    cycles = [sequence[n * duration:n * duration + duration] for n in range(num_cycles)]\n",
    "    \n",
    "    print('this method doesn\\'t work yet')\n",
    "    #return get_synchrony(cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this method doesn't work yet\n"
     ]
    }
   ],
   "source": [
    "sequence = [1,1,2,1,2,2,1,1,2,1,2,1,1,2,3,1,1,2]\n",
    "get_routine(sequence, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
